{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "#sklearn.cluster.\n",
    "import pickle\n",
    "import logging\n",
    "from time import time\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from soyclustering import SphericalKMeans\n",
    "#from sphere cluster import Spherical K Means\n",
    "#from spherecluster import SphericalKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.training_loss = []\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 1:\n",
    "            current_loss = loss\n",
    "        else:\n",
    "            current_loss = loss - self.loss_previous_step\n",
    "        print(f\"Loss after epoch {self.epoch}: {current_loss}\")\n",
    "        self.training_loss.append(current_loss)\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=341729, size=256, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "f = open('./song2vec_filtered_model_train_epoch_100.dat', 'rb')\n",
    "model=pickle.load(f)\n",
    "#list = f.readlines()\n",
    "#f.close()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woojung\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('239651', 0.9973549842834473),\n",
       " ('525280', 0.9889724254608154),\n",
       " ('541508', 0.9712550044059753),\n",
       " ('435340', 0.9097160696983337),\n",
       " ('214353', 0.8986788988113403),\n",
       " ('420356', 0.8914004564285278),\n",
       " ('264203', 0.8861410617828369),\n",
       " ('110380', 0.8835406303405762),\n",
       " ('373107', 0.8763835430145264),\n",
       " ('470836', 0.8757386207580566),\n",
       " ('237396', 0.874198317527771),\n",
       " ('37319', 0.8708698749542236),\n",
       " ('345194', 0.8698115348815918),\n",
       " ('626914', 0.8673614859580994),\n",
       " ('402002', 0.8641963601112366),\n",
       " ('633876', 0.8634134531021118),\n",
       " ('429931', 0.8627378940582275),\n",
       " ('199981', 0.8616964221000671),\n",
       " ('255742', 0.8595569133758545),\n",
       " ('690925', 0.8594090938568115)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('129204',topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341729, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = model.wv[model.wv.vocab.keys()]\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN 모델 ->  Elbow를 사용하여 K 구하기 -> t-SNE 사용하여 256차월을 3D로 나눠서 visualize 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphericalKmeans:\n",
    "    \"\"\"Spherical k-means clustering.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int, optional, default: 2\n",
    "        Number of clusters to form\n",
    "    init : numpy array or scipy sparse matrix, \\\n",
    "        shape (n_features, n_clusters), optional, default: None\n",
    "        Initial column labels\n",
    "    max_iter : int, optional, default: 20\n",
    "        Maximum number of iterations\n",
    "    n_init : int, optional, default: 1\n",
    "        Number of time the algorithm will be run with different\n",
    "        initializations. The final results will be the best output of `n_init`\n",
    "        consecutive runs.\n",
    "    random_state : integer or numpy.RandomState, optional\n",
    "        The generator used to initialize the centers. If an integer is\n",
    "        given, it fixes the seed. Defaults to the global numpy random\n",
    "        number generator.\n",
    "    tol : float, default: 1e-9\n",
    "        Relative tolerance with regards to criterion to declare convergence\n",
    "    weighting : boolean, default: True\n",
    "        Flag to activate or deactivate TF-IDF weighting\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    labels_ : array-like, shape (n_rows,)\n",
    "        cluster label of each row\n",
    "    criterion : float\n",
    "        criterion obtained from the best run\n",
    "    criterions : list of floats\n",
    "        sequence of criterion values during the best run\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters=2, init=None, max_iter=20, n_init=1,\n",
    "                 tol=1e-9, random_state=None, weighting=True):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.init = init\n",
    "        self.max_iter = max_iter\n",
    "        self.n_init = n_init\n",
    "        self.tol = tol\n",
    "        self.random_state = check_random_state(random_state)\n",
    "        self.labels_ = None\n",
    "        self.criterions = []\n",
    "        self.criterion = -np.inf\n",
    "        self.weighting = weighting\n",
    "        self.Z = None\n",
    "        self.Z_fuzzy = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Perform clustering.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array or scipy sparse matrix, shape=(n_samples, n_features)\n",
    "            Matrix to be analyzed\n",
    "        \"\"\"\n",
    "\n",
    "        check_array(X, pos=False)\n",
    "\n",
    "        check_numbers_clustering(X, self.n_clusters)\n",
    "\n",
    "        criterion = self.criterion\n",
    "\n",
    "        if self.weighting:\n",
    "            transformer = TfidfTransformer(norm='l2', smooth_idf=True)\n",
    "            X = transformer.fit_transform(X)\n",
    "\n",
    "        X = X.todense()\n",
    "        X = np.array(X)\n",
    "        X = sp.lil_matrix(X)\n",
    "        #X = sp.csr_matrix(X)\n",
    "        X = normalize(X)\n",
    "\n",
    "        #X = X.astype(float)\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "        seeds = random_state.randint(np.iinfo(np.int32).max, size=self.n_init)\n",
    "        for seed in seeds:\n",
    "            print(\" == New init == \")\n",
    "            self.random_state = seed\n",
    "            self._fit_single(X)\n",
    "            # remember attributes corresponding to the best criterion\n",
    "            if (self.criterion > criterion):\n",
    "                criterion = self.criterion\n",
    "                criterions = self.criterions\n",
    "                labels_ = self.labels_\n",
    "                z = self.Z\n",
    "                z_fuzzy = self.Z_fuzzy\n",
    "\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # update attributes\n",
    "        self.criterion = criterion\n",
    "        self.criterions = criterions\n",
    "        self.row_labels_ = labels_\n",
    "        self.Z = z\n",
    "        self.Z_fuzzy = z_fuzzy\n",
    "\n",
    "\n",
    "    def _fit_single(self, X, y=None):\n",
    "        \"\"\"Perform one run of clustering.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array or scipy sparse matrix, shape=(n_samples, n_features)\n",
    "            Matrix to be analyzed\n",
    "        \"\"\"\n",
    "        K = self.n_clusters\n",
    "\n",
    "        if self.init is None:\n",
    "            Z = random_init_clustering(K, X.shape[0], self.random_state)\n",
    "        else:\n",
    "            Z = np.matrix(self.init, dtype=float)\n",
    "\n",
    "        X = sp.lil_matrix(X)\n",
    "\n",
    "        Z = sp.lil_matrix(Z)  # random_init function returns a nd_array\n",
    "\n",
    "        change = True\n",
    "\n",
    "        c_init = -np.inf\n",
    "        c_list = []\n",
    "        n_iter = 0\n",
    "\n",
    "        while change and n_iter < self.max_iter:\n",
    "            print(\"iteration:\", n_iter)\n",
    "            change = False\n",
    "\n",
    "            # compute centroids (in fact only summation along cols)\n",
    "            centers = Z.T*X  # centers = sparse matrix\n",
    "\n",
    "            # normalize centroids\n",
    "            centers = normalize(centers)\n",
    "\n",
    "            # hard assignment\n",
    "            #Z=centers*X.T\n",
    "            Z1 = X * centers.T\n",
    "            Z1 = Z1.todense()\n",
    "            Z1 = np.array(Z1)\n",
    "            Z = np.zeros_like(Z1)\n",
    "            Z[np.arange(len(Z1)), Z1.argmax(1)] = 1\n",
    "            Z = sp.csc_matrix(Z)\n",
    "\n",
    "            # compute and check if cosine criterion still evolves\n",
    "            k_times_k = Z.T * X * centers.T\n",
    "            c = np.trace(k_times_k.todense())  # no trace for sp ...\n",
    "\n",
    "            if np.abs(c - c_init) > 1e-9:\n",
    "                c_init = c\n",
    "                change = True\n",
    "                c_list.append(c)\n",
    "                print(c)\n",
    "            n_iter += 1\n",
    "\n",
    "        self.criterion = c\n",
    "        self.criterions = c_list\n",
    "        part = Z.todense().argmax(axis=1).tolist()\n",
    "        self.labels_ = [item for sublist in part for item in sublist]\n",
    "        self.Z = Z\n",
    "        self.Z_fuzzy = Z1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean = SphericalKMeans(n_clusters=2, \n",
    "                        init=None, \n",
    "                        max_iter=20, \n",
    "                        #n_init=1, \n",
    "                        tol=1e-09, \n",
    "                        random_state=None)\n",
    "                        #weighting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = SphericalKMeans(#init='k-means++',\n",
    "                         max_iter=300,\n",
    "                         n_clusters=110,\n",
    "                         #n_init=5,\n",
    "                         #n_jobs=-1,\n",
    "                         #normalize=True,\n",
    "                         random_state=123,\n",
    "                         #tol=0.0001,\n",
    "                         verbose=0) \n",
    "#kmeans.fit(embedding_matrix)\n",
    "#kmeans_df=pd.DataFrame(kmeans.cluster_centers_)\n",
    "#.fit(X)\n",
    "#kmeans.fit(embedding_matrix[0])\n",
    "#kmeans_df = pd.DataFrame(kmeans.cluster_centers_, columns = ['Red', 'Green', 'Blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spherical_kmeans = SphericalKMeans(\n",
    "    n_clusters=1000,\n",
    "    max_iter=10,\n",
    "    verbose=1,\n",
    "    init='k-means++',\n",
    "    #sparsity='minimum_df',\n",
    "    minimum_df_factor=0.05\n",
    ")\n",
    "from scipy.sparse import csr_matrix\n",
    "csr = csr_matrix(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-36584b122942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#sparsity='minimum_df',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     minimum_df_factor=0.05)\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m      \u001b[1;31m# EVALUATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soyclustering\\_kmeans.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[0mIndex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0mbelongs\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soyclustering\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mdebug_directory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[0mmax_similar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_similar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum_df_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimum_df_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m             )\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soyclustering\\_kmeans.py\u001b[0m in \u001b[0;36mk_means\u001b[1;34m(X, n_clusters, init, sparsity, max_iter, verbose, tol, random_state, debug_directory, algorithm, max_similar, alpha, radius, epsilon, minimum_df_factor)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mdebug_directory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_similar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_similar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         radius=radius, epsilon=epsilon, minimum_df_factor=minimum_df_factor)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;31m# parallelisation of k-means runs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soyclustering\\_kmeans.py\u001b[0m in \u001b[0;36mkmeans_single\u001b[1;34m(X, n_clusters, max_iter, init, sparsity, verbose, tol, random_state, debug_directory, debug_header, algorithm, max_similar, alpha, radius, epsilon, minimum_df_factor)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         radius, epsilon, minimum_df_factor)\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soyclustering\\_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_single_banilla\u001b[1;34m(X, sparsity, n_clusters, centers, max_iter, verbose, tol, debug_directory, debug_header, radius, epsilon, minimum_df_factor)\u001b[0m\n\u001b[0;32m    460\u001b[0m         labels, distances = pairwise_distances_argmin_min(\n\u001b[0;32m    461\u001b[0m             X, centers, metric='cosine')\n\u001b[1;32m--> 462\u001b[1;33m         \u001b[0mcenters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m         \u001b[0minertia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soyclustering\\_kmeans.py\u001b[0m in \u001b[0;36m_update\u001b[1;34m(X, labels, distances, n_clusters)\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m             \u001b[0mcenters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurr_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m     \u001b[1;31m# L2 normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "range_k_clusters = (0,341729)\n",
    "kmeans_result = []\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "csr = csr_matrix(embedding_matrix)\n",
    "\n",
    "for k in range(*range_k_clusters):\n",
    "    # CLUSTERING\n",
    "    spherical_kmeans = SphericalKMeans(\n",
    "    n_clusters=k,\n",
    "    max_iter=10,\n",
    "    verbose=1,\n",
    "    init='k-means++',\n",
    "    #sparsity='minimum_df',\n",
    "    minimum_df_factor=0.05)\n",
    "    kmeans = kmeans.fit_predict(csr)\n",
    " \n",
    "     # EVALUATE\n",
    "     #WCSS = kmeans.inertia_\n",
    " \n",
    "    kmeans_result.append(metric)\n",
    "kmeans_result = pd.DataFrame(kmeans_result)\n",
    "print(kmeans_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.fit_predict(csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('./spherical_labels.dat', 'wb')\n",
    "pickle.dump(labels, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./spherical_labels.dat', 'rb')\n",
    "label=pickle.load(f)\n",
    "#list = f.readlines()\n",
    "#f.close()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels) #train.data의 길이 341729  * 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=pd.DataFrame(labels)\n",
    "label.columns=[\"WCSS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label\n",
    "label.to_csv(\"WCSS.csv\",mode='w')\n",
    "dataset=pd.read_csv(\"WCSS.csv\", index_col=0)\n",
    "dataset.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#labb.plot.line()\n",
    "#plt.show()\n",
    "plt.plot(labb)\n",
    "plt.plot(np.arrange(len(labb)),labb[\"WCSS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 KNN 모델에서 Elbow를 구하여 K 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def locateOptimalElbow(x, y):\n",
    "    # START AND FINAL POINTS\n",
    "    p1 = (x[0], y[0])\n",
    "    p2 = (x[-1], y[-1])\n",
    "    \n",
    "    # EQUATION OF LINE: y = mx + c\n",
    "    m = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
    "    c = (p2[1] - (m * p2[0]))\n",
    "    # DISTANCE FROM EACH POINTS TO LINE mx - y + c = 0\n",
    "    a, b = m, -1\n",
    "    dist = np.array([abs(a*x0+b*y0+c)/math.sqrt(a**2+b**2) for x0, y0 in zip(x,y)])\n",
    "    return np.argmax(dist) + x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_opt = locateOptimalElbow(label.index, label['WCSS'].values)\n",
    "type(k_opt)\n",
    "k_opt\n",
    "\n",
    "# optimal_K 값을 'WCSS'의 Metric를 사용하여 계산\n",
    "#skm_opt=pd.DataFrame({'skm_opt':k_opt})\n",
    "#skm_opt=pd.concat([label, skm_opt],axis=1)\n",
    "#skm_opt = label.loc[k_opt, \"skm_object\"]\n",
    "#skm_opt\n",
    "#최적의 K 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_cluster = songs.copy()\n",
    "songs_cluster.loc[model.wv.vocab.keys(), 'cluster'] = skm_opt.labels_\n",
    "songs_cluster['cluster'] = songs_cluster['cluster'].fillna(-1).astype('int').astype('category')\n",
    "songs_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, n_clusters, max_iters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iters = max_iters\n",
    "        ...\n",
    "\n",
    "    def fit(self, x):\n",
    "        x = normalize(x, norm='l2')\n",
    "        self.cluster_center_ = np.zeros((self.n_clusters, x.shape[1]))\n",
    "        for iter_ in range(self.max_iters):\n",
    "           ...\n",
    "           self._centroid_update(x, labels)\n",
    "           ...\n",
    "\n",
    "    def _centroid_update(self, x, labels):\n",
    "        for c in range(self.n_clusters):\n",
    "            idxs = np.where(labels == c)[0]\n",
    "            x_cluster = x[idxs,:]\n",
    "            #k-means\n",
    "            #self.cluster_center_[c,:] = x_cluster.sum(axis=0) / idxs.shape[0]\n",
    "            \n",
    "            #spherical k-means\n",
    "            self.cluster_center_[c,:] = normalize(x_cluster.sum(axis=0), norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#알고리즘이 수렴하지 않는 문제가 발생할 수 있으므로, 이를 피하기 위하여 initialization method 를 \"random\"이 아닌 \"k-means ++\" 를 이용\n",
    "#K값과 군집에 대한 해석은 분석자의 감에 의존할 수도 있음\n",
    "##이를 방지하기 위하여 군집을 직접 \"plotting\" 해보거나 \"Within Cluster Sum of Squared (Cluster inertia)\"를 k값 별로 구하여 elbow point 찾는것에 도움이 됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow(x,n_k): #sum of squared distance using sklearn\n",
    "    sse=[]\n",
    "    for i in range(1, n_k+1):\n",
    "        km=KMeans(n_clusters=i, init=\"k-means++\").fit(x)\n",
    "        sse.append(km.inertia_)\n",
    "    return  sse, range(1,n_k+1)\n",
    "##plotting Within_cluster sum of suqares(=cluster inertia) to choose 'K'\n",
    "def wcss(input, k):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    Info=elbow(input,k)\n",
    "    plt.plot (Info[1], Info[0], marker='o', color='c')\n",
    "    plt.xticks(Info[1])\n",
    "    plt.xlabel (\"K\")\n",
    "    plt.ylabel (\"Total Squared Error\")\n",
    "    plt.title(\"Within #Cluster sum of squares\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##clusture the data using the von-mises fisher distribution\n",
    "#getting the size of the data\n",
    "def sphericalknn (data,no_clusters):\n",
    "    \n",
    "    H=len(data)\n",
    "    W=len(data[0])\n",
    "    \n",
    "#calculating the mean to remove the dc component\n",
    "    sum_sample=sum(data)\n",
    "    norm_sample=np.linalg.norm(sum_sample)\n",
    "    mean_sample=(sum_sample)/(norm_sample)\n",
    "\n",
    "#calculating global mean to get centroids of the clusters\n",
    "    deviation=0.01\n",
    "    mean_global = np.zeros([no_clusters,W])\n",
    "    for i in range (0,no_clusters):\n",
    "        random_sample=np.random.rand(1,W)-0.5\n",
    "        random_norm=deviation*(np.random.rand())\n",
    "        random_sample2=(random_norm*random_sample)/np.linalg.norm(random_sample)\n",
    "        temp = mean_sample+random_sample2\n",
    "        mean_global[i,:] = temp/np.linalg.norm(temp)\n",
    "\n",
    "#print(mean_globalf)   \n",
    "#calculating mean from spherical kmeans\n",
    "\n",
    "    sum_sample3 = np.zeros([1,W])\n",
    "    difference=1\n",
    "    epsilon=0.01\n",
    "    number=100\n",
    "    iteration=0\n",
    "\n",
    "    while (difference>epsilon):\n",
    "        #check\n",
    "        iteration=iteration+1\n",
    "        number2=number\n",
    "        #computing the nearest neighbour and assigning the points\n",
    "        mean_global2 = np.transpose(mean_global)\n",
    "        value=np.dot(data, mean_global2)\n",
    "        value_max=value.max(1)\n",
    "        clusters=np.argmax(value,axis=1)\n",
    "    \n",
    "    #computing value of the function\n",
    "        number=sum(value_max) \n",
    "    #print(number)\n",
    "\n",
    "    #computing centroids for the clusters\n",
    "        for i in range(0,no_clusters):\n",
    "            sum_sample3=sum(data[np.where(clusters==i)])\n",
    "            if(mpmath.norm(sum_sample3) != 0):\n",
    "                temp2=sum_sample3/mpmath.norm(sum_sample3)#np.linalg.norm(sum_sample3) #Check this\n",
    "                mean_global[i,:] = temp2\n",
    "\n",
    "        \n",
    "        difference=abs(number-number2)\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-55aa1e969665>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m  \u001b[1;31m# to normalise existing X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_Norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'random'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing  # to normalise existing X\n",
    "X_Norm = preprocessing.normalize(embedding_matrix)\n",
    "\n",
    "km2 = cluster.KMeans(n_clusters=5,init='random').fit(X_Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_cosine_fit(sparse_data, nclust = 10, njobs=-1, randomstate=None):\n",
    "    # Manually override euclidean\n",
    "    def euc_dist(X, Y = None, Y_norm_squared = None, squared = False):\n",
    "        #return pairwise_distances(X, Y, metric = 'cosine', n_jobs = 10)\n",
    "        return np.arccos(cosine_similarity(X, Y))/np.pi\n",
    "    k_means_.euclidean_distances = euc_dist\n",
    "    kmeans = k_means_.KMeans(n_clusters = nclust, n_jobs = njobs, random_state = randomstate)\n",
    "    _ = kmeans.fit(sparse_data)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sparse_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-92a12c5a7662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKMeans_cosine_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnclust\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnjobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandomstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m ''''spherical_kmeans = SphericalKMeans(n_init='k-means++', \n\u001b[0;32m      3\u001b[0m                                    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                    \u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                    \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sparse_data' is not defined"
     ]
    }
   ],
   "source": [
    "kmeans=KMeans_cosine_fit(sparse_data, nclust=110, njobs=-1, randomstate=123)\n",
    "\n",
    "''''spherical_kmeans = SphericalKMeans(n_init='k-means++', \n",
    "                                   max_iter=300, \n",
    "                                   n_clusters=110,\n",
    "                                   n_init=5, \n",
    "                                   n_jobs=-1, \n",
    "                                   normalize=True, \n",
    "                                   random_state=123, \n",
    "                                   tol=0.0001, \n",
    "                                   verbose=0)\n",
    "\n",
    "#labels = spherical_kmeans.fit_predict(x)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'songs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-c36241091ed9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msongs_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msongs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msongs_cluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cluster'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskm_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msongs_cluster\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msongs_cluster\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msongs_cluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'songs' is not defined"
     ]
    }
   ],
   "source": [
    "songs_cluster = songs.copy()\n",
    "songs_cluster.loc[model.wv.vocab.keys(), 'cluster'] = skm_opt.labels_\n",
    "songs_cluster['cluster'] = songs_cluster['cluster'].fillna(-1).astype('int').astype('category')\n",
    "songs_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'locateOptimalElbow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ec877a56ae86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mk_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocateOptimalElbow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskm_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskm_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'WCSS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mskm_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskm_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"skm_object\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mskm_opt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'locateOptimalElbow' is not defined"
     ]
    }
   ],
   "source": [
    "k_opt = locateOptimalElbow(skm_df.index, skm_df['WCSS'].values)\n",
    "skm_opt = skm_df.loc[k_opt, \"skm_object\"]\n",
    "skm_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedded_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-f18066cd6909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0membedded_matrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mkmeanModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mkmeanModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdistortions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmeanModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mkmeanModel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embedded_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "for k in embedded_matrix:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(df)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "kmeanModel=KMeans(n_clusters =3)\n",
    "kmeanModel.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-fd7297bc4b77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msoyclustering\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSphericalKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspherical_kmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSphericalKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-means++'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_cluster\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspherical_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_cluster'"
     ]
    }
   ],
   "source": [
    "from soyclustering import SphericalKMeans\n",
    "spherical_kmeans = SphericalKMeans(init='k-means++', max_iter=300, n_cluster=110, n_init=5, n_jobs=-1, normalize =True, random_state=123,tol=0.0001, verbose=0)\n",
    "\n",
    "labels = spherical_kmeans.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
